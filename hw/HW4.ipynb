{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e63rmXOtVyys"
      },
      "source": [
        "# Homework 4\n",
        "\n",
        "**Name:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Name = \"Matt Burns\"\n",
        "assert Name != \"\", 'Please enter your name in the above quotation marks, thanks!'"
      ],
      "metadata": {
        "id": "j8FM40ov2eFn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oxtoxlQYJWe"
      },
      "source": [
        "**A-Number:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A_number = \"\"\n",
        "assert A_number != \"\", 'Please enter your A-number in the above quotation marks, thanks!'"
      ],
      "metadata": {
        "id": "NJgxTGC63I0Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YST4g_loYMU8"
      },
      "source": [
        "**Kaggle-UserName:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Kaggle_UserName = \"\"\n",
        "assert Kaggle_UserName != \"\", 'Please enter your Kaggle Username in the above quotation marks, thanks!'"
      ],
      "metadata": {
        "id": "YjXJGB4e3Kwd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz5LfPpXDhFl"
      },
      "source": [
        "**Please describe your improvements here**:\n",
        "\n",
        "* Code is adapted from the following sources: https://github.com/fastai/imagenette\n",
        "* GPT-4 utilized: https://chat.openai.com/share/c964473d-ab9c-4f07-be8d-bec5bef536ac\n",
        "\n",
        "* Implemented a MaxBlurPool2D layer\n",
        "* Utilize a mish activation function\n",
        "* Custom self attention layer\n",
        "* Utilize a 50% dropout layer\n",
        "* Image transformations\n",
        "* Utilize built-in early stopping and checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG8E84ytDhFl"
      },
      "source": [
        "In this homework, we will train a CNN model to classify big cats. This dataset consists of images of ten types of big cats, a.k.a, multiclass classification.\n",
        "\n",
        " **Please download the dataset from the [inclass Kaggle competition](https://www.kaggle.com/t/e5a7bab3f6c543a9943b3d9970768eaa) as we split the original dataset into the train-valid-test sets.**\n",
        "\n",
        "This notebook contains a baseline model. Please use it as a starting point. **The purpose of this homework is to design an advanced CNN model to achieve better performance by yourself. You are not allowed to import pre-trained models. In case you are interested, we provide a sample code by using a pre-trained model, Resnet50.**\n",
        "\n",
        "Your jobs\n",
        "\n",
        "-   Read, complete, and run the code.\n",
        "\n",
        "-   **Make substantial improvements** to maximize the accurcy.\n",
        "\n",
        "-   Submit the .IPYNB file to Canvas.\n",
        "\n",
        "    - Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`.\n",
        "    \n",
        "    - Notebooks with cell execution numbers out of order will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
        "    \n",
        "    - Please keep your notebook clean and delete any throwaway code.\n",
        "\n",
        "-   Submit the generated \"pred.csv\" to the [inclass Kaggle competition](https://www.kaggle.com/t/e5a7bab3f6c543a9943b3d9970768eaa).\n",
        "\n",
        "\n",
        "# **Rules**\n",
        "\n",
        "- You should finish your homework on your own.\n",
        "- **You should not modify your prediction files manually.**\n",
        "- Do not share code or prediction files with any living creatures.\n",
        "- **Do not search or use additional data.**\n",
        "- **Do not use any pre-trained models.**\n",
        "    - You can ask Github copilot for help.\n",
        "\n",
        "\n",
        "## Hints to Improve Your Results\n",
        "\n",
        "* You'd better use a GPU machine to run it, otherwise it'll be quite slow.\n",
        "* Revise the simple CNN model\n",
        "* Revise the *transforms* function by using some image augumentation techniques\n",
        "* Tune hyper-parameters, such as batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zycIabnMx6kL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed040fc-e17c-42fd-9bd7-2ab03a204875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow matplotlib tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bgrW0Si3xuNF"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g92P7NiwCn1x",
        "outputId": "b75a2fb5-6044-44af-b3f9-4afca33dcec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available and set TensorFlow device to GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(f'{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs')\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No GPU is available.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "BLR9CbUBzGA-",
        "outputId": "ba5671ec-da24-408a-b171-1bd86d10234b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cf7ec7ac-cb4f-4d2e-80b1-e93730bbef53\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cf7ec7ac-cb4f-4d2e-80b1-e93730bbef53\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (2).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (2).json': b'{\"username\":\"\",\"key\":\"\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()   ## Upload your Kaggle token file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riJYzXqAzzIn",
        "outputId": "c53d3907-999a-41e3-d068-3aa0d7127046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fall2023-cs5665-hw4.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c fall2023-cs5665-hw4   ## You need to join the competition first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "POHPPf_09A-J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "local_zip = 'fall2023-cs5665-hw4.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('./')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XSNWVpjW_HKb"
      },
      "outputs": [],
      "source": [
        "# Define MaxBlurPool2D layer (mimicking the FastAI MaxBlurPool technique)\n",
        "class MaxBlurPool2D(layers.Layer):\n",
        "    def __init__(self, pool_size=(2, 2), strides=(2, 2), padding='valid', **kwargs):\n",
        "        super(MaxBlurPool2D, self).__init__(**kwargs)\n",
        "        self.pool_size = pool_size\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        self.max_pool = layers.MaxPooling2D(pool_size=self.pool_size, strides=self.strides, padding=self.padding)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Create a 3x3 gaussian blur kernel\n",
        "        kernel_vals = np.array([1, 2, 1], dtype=np.float32)\n",
        "        kernel_vals = kernel_vals[:, np.newaxis] * kernel_vals[np.newaxis, :]\n",
        "        kernel_vals /= np.sum(kernel_vals)\n",
        "        blur_kernel = np.tile(kernel_vals[:, :, np.newaxis, np.newaxis], (1, 1, input_shape[-1], 1))\n",
        "        self.blur_kernel = tf.constant(blur_kernel, dtype=tf.float32)\n",
        "        super(MaxBlurPool2D, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.max_pool(inputs)\n",
        "        # Add blur effect using depthwise_conv2d\n",
        "        return tf.nn.depthwise_conv2d(input=x, filter=self.blur_kernel, strides=[1, 1, 1, 1], padding='SAME')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qt51pux6ADmt"
      },
      "outputs": [],
      "source": [
        "# Define a custom Mish activation function\n",
        "def mish(x):\n",
        "    return x * tf.math.tanh(tf.math.softplus(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uOW76eukAGRB"
      },
      "outputs": [],
      "source": [
        "# Define a custom Self-Attention Layer\n",
        "class SelfAttention(layers.Layer):\n",
        "    def __init__(self, channels, **kwargs):\n",
        "        super(SelfAttention, self).__init__(**kwargs)\n",
        "        self.channels = channels\n",
        "        self.query = layers.Dense(channels)\n",
        "        self.key = layers.Dense(channels)\n",
        "        self.value = layers.Dense(channels)\n",
        "        self.gamma = self.add_weight(name='gamma', shape=[1], initializer='zeros', trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        shape = tf.shape(inputs)\n",
        "        f = self.query(inputs)  # [bs, h*w, c']\n",
        "        g = self.key(inputs)    # [bs, h*w, c']\n",
        "        h = self.value(inputs)  # [bs, h*w, c']\n",
        "\n",
        "        s = tf.matmul(g, f, transpose_b=True)  # [bs, h*w, h*w]\n",
        "        beta = tf.nn.softmax(s, axis=-1)  # attention map\n",
        "\n",
        "        o = tf.matmul(beta, h)  # [bs, h*w, c']\n",
        "        o = tf.reshape(o, shape=shape)  # [bs, h, w, c]\n",
        "        x = self.gamma * o + inputs\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BsKXPhp39IN-"
      },
      "outputs": [],
      "source": [
        "# Set up the image data generator with preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,  # Add vertical flip\n",
        "    channel_shift_range=20,  # Shift the channels by up to 20 values\n",
        "    fill_mode='reflect'  # Use 'reflect' mode for filling in new pixels\n",
        "    # fill_mode='nearest'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RK64Ak7B9JlQ"
      },
      "outputs": [],
      "source": [
        "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlmqNO9d9MtH",
        "outputId": "d6313c80-826b-4a15-db2b-1c0d9b2393b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2111 images belonging to 10 classes.\n",
            "Found 50 images belonging to 10 classes.\n",
            "Found 278 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "# Set up train and validation generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    './Dataset/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    './Dataset/val',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = valid_datagen.flow_from_directory(\n",
        "    './Dataset/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "M-ffW_a19Z47"
      },
      "outputs": [],
      "source": [
        "base_model = ResNet50(weights=None, include_top=False, input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "miKwkWHX9do1"
      },
      "outputs": [],
      "source": [
        "from keras.api._v2.keras import models\n",
        "\n",
        "# Create a new model on top with MaxBlurPool\n",
        "with tf.device('/GPU:0'): model = models.Sequential([\n",
        "    base_model,\n",
        "    MaxBlurPool2D(),\n",
        "    SelfAttention(base_model.output_shape[-1]),\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(1024),\n",
        "    layers.Lambda(mish),\n",
        "    Dropout(0.5),\n",
        "    layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QZPEg3ZJ9hkG"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMUlosMHI_J4",
        "outputId": "34df149a-c158-4f33-82ec-c7ff7f47cf61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from google.colab import drive\n",
        "\n",
        "# Define the early stopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor the validation loss\n",
        "    patience=25,          # Number of epochs with no improvement after which training will be stopped\n",
        "    verbose=1,           # Verbosity mode\n",
        "    restore_best_weights=True  # Whether to restore model weights from the epoch with the best value of the monitored quantity\n",
        ")\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the checkpoint callback\n",
        "checkpoint = ModelCheckpoint(\n",
        "    '/content/drive/My Drive/model_ranger.h5',  # Path where to save the model\n",
        "    monitor='val_accuracy',  # Metric to monitor\n",
        "    verbose=1,  # Logging level\n",
        "    save_best_only=True,  # Only save a model if `val_accuracy` has improved\n",
        "    mode='max'  # `max` means that `val_accuracy` should be maximized\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9rHB8ni9kXA",
        "outputId": "86e1b6b9-dd30-41bc-db28-733993815f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 3.8920 - accuracy: 0.1304\n",
            "Epoch 1: val_accuracy improved from -inf to 0.09375, saving model to /content/drive/My Drive/model_ranger.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r65/65 [==============================] - 65s 478ms/step - loss: 3.8920 - accuracy: 0.1304 - val_loss: 2.6769 - val_accuracy: 0.0938\n",
            "Epoch 2/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 2.1063 - accuracy: 0.2165\n",
            "Epoch 2: val_accuracy improved from 0.09375 to 0.12500, saving model to /content/drive/My Drive/model_ranger.h5\n",
            "65/65 [==============================] - 26s 395ms/step - loss: 2.1063 - accuracy: 0.2165 - val_loss: 3.6342 - val_accuracy: 0.1250\n",
            "Epoch 3/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.8969 - accuracy: 0.2549\n",
            "Epoch 3: val_accuracy improved from 0.12500 to 0.18750, saving model to /content/drive/My Drive/model_ranger.h5\n",
            "65/65 [==============================] - 26s 394ms/step - loss: 1.8969 - accuracy: 0.2549 - val_loss: 1.9149 - val_accuracy: 0.1875\n",
            "Epoch 4/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.7465 - accuracy: 0.3151\n",
            "Epoch 4: val_accuracy improved from 0.18750 to 0.40625, saving model to /content/drive/My Drive/model_ranger.h5\n",
            "65/65 [==============================] - 26s 392ms/step - loss: 1.7465 - accuracy: 0.3151 - val_loss: 1.5764 - val_accuracy: 0.4062\n",
            "Epoch 5/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.6785 - accuracy: 0.3449\n",
            "Epoch 5: val_accuracy did not improve from 0.40625\n",
            "65/65 [==============================] - 24s 369ms/step - loss: 1.6785 - accuracy: 0.3449 - val_loss: 1.7488 - val_accuracy: 0.2812\n",
            "Epoch 6/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.5495 - accuracy: 0.4040\n",
            "Epoch 6: val_accuracy did not improve from 0.40625\n",
            "65/65 [==============================] - 24s 364ms/step - loss: 1.5495 - accuracy: 0.4040 - val_loss: 3.4395 - val_accuracy: 0.1875\n",
            "Epoch 7/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.4731 - accuracy: 0.4209\n",
            "Epoch 7: val_accuracy improved from 0.40625 to 0.53125, saving model to /content/drive/My Drive/model_ranger.h5\n",
            "65/65 [==============================] - 29s 444ms/step - loss: 1.4731 - accuracy: 0.4209 - val_loss: 6.5353 - val_accuracy: 0.5312\n",
            "Epoch 8/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.4306 - accuracy: 0.4324\n",
            "Epoch 8: val_accuracy did not improve from 0.53125\n",
            "65/65 [==============================] - 24s 366ms/step - loss: 1.4306 - accuracy: 0.4324 - val_loss: 1.6401 - val_accuracy: 0.3750\n",
            "Epoch 9/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.4405 - accuracy: 0.4444\n",
            "Epoch 9: val_accuracy did not improve from 0.53125\n",
            "65/65 [==============================] - 24s 367ms/step - loss: 1.4405 - accuracy: 0.4444 - val_loss: 1.3732 - val_accuracy: 0.4688\n",
            "Epoch 10/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.3491 - accuracy: 0.4733\n",
            "Epoch 10: val_accuracy did not improve from 0.53125\n",
            "65/65 [==============================] - 24s 364ms/step - loss: 1.3491 - accuracy: 0.4733 - val_loss: 2.0069 - val_accuracy: 0.4062\n",
            "Epoch 11/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.2893 - accuracy: 0.4998\n",
            "Epoch 11: val_accuracy did not improve from 0.53125\n",
            "65/65 [==============================] - 24s 366ms/step - loss: 1.2893 - accuracy: 0.4998 - val_loss: 1.6700 - val_accuracy: 0.4688\n",
            "Epoch 12/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.2587 - accuracy: 0.5204\n",
            "Epoch 12: val_accuracy did not improve from 0.53125\n",
            "65/65 [==============================] - 24s 366ms/step - loss: 1.2587 - accuracy: 0.5204 - val_loss: 2.1524 - val_accuracy: 0.4688\n",
            "Epoch 13/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.2347 - accuracy: 0.5233\n",
            "Epoch 13: val_accuracy did not improve from 0.53125\n",
            "65/65 [==============================] - 24s 366ms/step - loss: 1.2347 - accuracy: 0.5233 - val_loss: 2.1530 - val_accuracy: 0.3750\n",
            "Epoch 14/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.1934 - accuracy: 0.5421\n",
            "Epoch 14: val_accuracy did not improve from 0.53125\n",
            "65/65 [==============================] - 24s 365ms/step - loss: 1.1934 - accuracy: 0.5421 - val_loss: 2.0774 - val_accuracy: 0.3438\n",
            "Epoch 15/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.1508 - accuracy: 0.5671\n",
            "Epoch 15: val_accuracy did not improve from 0.53125\n",
            "65/65 [==============================] - 24s 364ms/step - loss: 1.1508 - accuracy: 0.5671 - val_loss: 1.4771 - val_accuracy: 0.4688\n",
            "Epoch 16/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.1244 - accuracy: 0.5743\n",
            "Epoch 16: val_accuracy did not improve from 0.53125\n",
            "65/65 [==============================] - 24s 364ms/step - loss: 1.1244 - accuracy: 0.5743 - val_loss: 1.4693 - val_accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.1045 - accuracy: 0.5729\n",
            "Epoch 17: val_accuracy did not improve from 0.53125\n",
            "65/65 [==============================] - 23s 360ms/step - loss: 1.1045 - accuracy: 0.5729 - val_loss: 1.5044 - val_accuracy: 0.3750\n",
            "Epoch 18/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.0691 - accuracy: 0.5897\n",
            "Epoch 18: val_accuracy did not improve from 0.53125\n",
            "65/65 [==============================] - 24s 364ms/step - loss: 1.0691 - accuracy: 0.5897 - val_loss: 1.7411 - val_accuracy: 0.4688\n",
            "Epoch 19/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.0542 - accuracy: 0.5878\n",
            "Epoch 19: val_accuracy improved from 0.53125 to 0.68750, saving model to /content/drive/My Drive/model_ranger.h5\n",
            "65/65 [==============================] - 30s 459ms/step - loss: 1.0542 - accuracy: 0.5878 - val_loss: 1.1872 - val_accuracy: 0.6875\n",
            "Epoch 20/20\n",
            "65/65 [==============================] - ETA: 0s - loss: 1.0474 - accuracy: 0.6041\n",
            "Epoch 20: val_accuracy did not improve from 0.68750\n",
            "65/65 [==============================] - 24s 367ms/step - loss: 1.0474 - accuracy: 0.6041 - val_loss: 1.2291 - val_accuracy: 0.5625\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.ops import custom_gradient\n",
        "# Add the checkpoint to your list of callbacks\n",
        "callbacks_list = [early_stopping, checkpoint]\n",
        "# callsbacks_list = [checkpoint]\n",
        "\n",
        "#custom_objects = {'SelfAttention': SelfAttention, 'MaxBlurPool2D': MaxBlurPool2D}\n",
        "\n",
        "#model = tf.keras.models.load_model('best_model_2', custom_objects=custom_objects)\n",
        "\n",
        "# Start training\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=valid_generator.samples // valid_generator.batch_size,\n",
        "    epochs=20,\n",
        "    callbacks=callbacks_list\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('model.h5')\n",
        "\n",
        "# Save the model to Google Drive\n",
        "model.save('/content/drive/My Drive/model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import custom_object_scope\n",
        "import pandas as pd\n",
        "\n",
        "def make_predictions_and_export(model_path, test_data_path, output_csv_path):\n",
        "    \"\"\"\n",
        "    Loads a trained model, makes predictions on the test dataset, and exports the predictions to a CSV file.\n",
        "\n",
        "    :param model_path: Path to the trained model file.\n",
        "    :param test_data_path: Path to the test dataset directory or file.\n",
        "    :param output_csv_path: Path where the output CSV file will be saved.\n",
        "    \"\"\"\n",
        "    # Load the model\n",
        "    with custom_object_scope({'SelfAttention': SelfAttention, 'MaxBlurPool2D': MaxBlurPool2D}):\n",
        "        model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "\n",
        "    # Prepare the test dataset\n",
        "    # Assuming the test data is in a directory and organized in a way that can be used with ImageDataGenerator\n",
        "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_data_path,\n",
        "        target_size=(224, 224),  # Assuming the model expects images of this size\n",
        "        batch_size=32,\n",
        "        class_mode=None,  # Since we're predicting, we don't need labels\n",
        "        shuffle=False  # Keep data in same order as labels\n",
        "    )\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(test_generator, verbose=1)\n",
        "\n",
        "    # Assuming the predictions are categorical, get the class with the highest probability\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Create a DataFrame with the required structure\n",
        "    ids = range(len(predicted_classes))  # Assuming IDs should be a range starting from 0\n",
        "    results_df = pd.DataFrame({'id': ids, 'label': predicted_classes})\n",
        "\n",
        "    # Export to CSV\n",
        "    results_df.to_csv(output_csv_path, index=False)\n",
        "    print(f'Predictions are exported to {output_csv_path}')"
      ],
      "metadata": {
        "id": "NIQLAxfo5s-o"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions_and_export(\n",
        "    model_path='model.h5',\n",
        "    test_data_path='./Dataset/test',\n",
        "    output_csv_path='pred.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyQbKx-J57CS",
        "outputId": "755d7eaa-03b6-459b-b8b9-1fb4c5a109e1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 278 images belonging to 1 classes.\n",
            "9/9 [==============================] - 2s 97ms/step\n",
            "Predictions are exported to pred.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
